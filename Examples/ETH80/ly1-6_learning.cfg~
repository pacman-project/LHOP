
############################################################################################################
########################################## Inference for each layer ########################################
############################################################################################################

inference.ly1.result_extension               = .ly1
inference.ly2.result_extension               = .ly2
inference.ly3.result_extension               = .ly3
inference.ly4.result_extension               = .ly4
inference.ly5.result_extension               = .ly5
inference.ly6.result_extension               = .ly6
inference.ly7.result_extension               = .ly7

#################################
#### Inference for layer one ####
#################################

inference.ly1.type                  = struct
inference.ly1.region_lambda_factor  = 0.8
inference.ly1.layer1_threshold      = 0.1
inference.ly1.power_correction      = 0.6
inference.ly1.init_size             = -50
inference.ly1.scale_limit           = 1000
inference.ly1.border_size           = 100
inference.ly1.scale_factor          = 0.707
inference.ly1.response_percent      = 0.6
inference.ly1.result_extension      = .ly1


############################################################
#### Config values for layer adding, layer 1 -> layer 2 ####
############################################################

inference.ly2.layer_contraction = 2.0
inference.ly2.g_response_threshold = 0.8
inference.ly2.r_response_threshold = 0.3
inference.ly2.candidate_r_threshold = 0.25
inference.ly2.candidate_g_threshold = 0.4
inference.ly2.g_response_pow = 0.6
inference.ly2.candidate_g_threshold_percent = 0.35
inference.ly2.realization_ratio_threshold = 0.9
inference.ly2.ignore_g_distribution = true
inference.ly2.normalize_histogram = true
inference.ly2.add_edge_names = true
inference.ly2.convolution_link_threshold = 0.95
inference.ly2.result_extension      = .ly2

############################################################
#### config values for layer adding, layer 2 -> layer 3 ####
############################################################

inference.ly3.layer_contraction = 2.0
inference.ly3.g_response_threshold = 0.6
inference.ly3.r_response_threshold = 0.35
inference.ly3.candidate_r_threshold = 0.25
inference.ly3.candidate_g_threshold = 0.4
inference.ly3.g_response_pow = 0.6
inference.ly3.candidate_g_threshold_percent = 0.32
inference.ly3.realization_ratio_threshold = 0.8
inference.ly3.ignore_g_distribution = true
inference.ly3.normalize_histogram = true
inference.ly3.add_edge_names = true
inference.ly3.convolution_link_threshold = 0.95

#inference.ly3.shape_check  = true
#inference.ly3.s_response_threshold = 0.3

############################################################
#### Config values for layer adding, layer 3 -> layer 4 ####
############################################################

inference.ly4.layer_contraction = 1.5
inference.ly4.g_response_threshold = 0.4
inference.ly4.r_response_threshold = 0.1
inference.ly4.candidate_r_threshold = 0.1
inference.ly4.candidate_g_threshold = 0.1
inference.ly4.g_response_pow = 0.6
inference.ly4.realization_ratio_threshold = 0.70
inference.ly4.ignore_g_distribution = true
inference.ly4.normalize_histogram = true
inference.ly4.add_edge_names = true
inference.ly4.convolution_link_threshold = 0.95

############################################################
#### Config values for layer adding, layer 4 -> layer 5 ####
############################################################

inference.ly5.layer_contraction = 1.0
inference.ly5.g_response_threshold = 0.1
inference.ly5.r_response_threshold = 0.05
inference.ly5.candidate_r_threshold = 0.05
inference.ly5.candidate_g_threshold = 0.05
inference.ly5.g_response_pow = 0.6
inference.ly5.realization_ratio_threshold = 0.85
inference.ly5.ignore_g_distribution = true
inference.ly5.normalize_histogram = true
inference.ly5.add_edge_names = true
inference.ly5.convolution_link_threshold = 0.95

inference.ly5.shape_check  = true
inference.ly5.s_response_threshold = 2.0


############################################################
#### Config values for layer adding, layer 5 -> layer 6 ####
############################################################

inference.ly6.layer_contraction       = 1.0
inference.ly6.g_response_threshold    = 0.05
inference.ly6.r_response_threshold    = 0.01
inference.ly6.candidate_r_threshold   = 0.01
inference.ly6.candidate_g_threshold   = 0.01
inference.ly6.convolution_threshold   = 0.01
inference.ly6.g_response_pow          = 0.9
inference.ly6.realization_ratio_threshold = 0.5
#inference.ly6.min_factor             = 0.8
#inference.ly6.max_factor             = 1.2
inference.ly6.reconstruction_type    = 9
inference.ly6.ignore_g_distribution = true
inference.ly6.add_edge_names         = true
inference.ly6.result_extension = .ly5
inference.ly6.shape_check  = true
inference.ly6.s_response_threshold   = 5
#inference.ly6.normalize_histogram = true
#inference.ly6.shape_distance_threshold = 20
#inference.ly6.shape_sc_threshold = 6
inference.ly6.convolution_link_threshold = 0.95


############################################################
#### Config values for layer adding, layer 6 -> layer 7 ####
############################################################
inference.ly7.layer_contraction      = 1
inference.ly7.r_response_threshold   = 0.000
inference.ly7.g_response_threshold   = 0.000
inference.ly7.candidate_r_threshold   = 0.000
inference.ly7.candidate_g_threshold   = 0.000
inference.ly7.convolution_threshold   = 0.000
inference.ly7.convolution_threshold   = 0.00
inference.ly7.identity_g_response    = true
inference.ly7.realization_ratio_threshold = 0.0
inference.ly7.reconstruction_type    = 3
inference.ly7.copy_prev_layer        = false
inference.ly7.ignore_g_distribution  = true
 
############################################################################################################
########################################## Optimization learning ###########################################
############################################################################################################
#learning.action = optimization

learning.optimization.overall_steps         = 1

learning.optimization.save_test_set         = true # display res*.lyX files
learning.res_export_name                    = res/res

learning.optimization.optimization_type        = default
learning.optimization.min_layer             = 2
learning.optimization.max_layer             = 5
learning.optimization.start_layer           = 2
learning.optimization.end_layer             = 5


learning.optimization.ly2.part_max_number = 20
learning.optimization.ly2.cluster_size = 5
learning.optimization.ly2.library_image = lib2.png
learning.optimization.ly2.library_image_sc = lib2sc.png
learning.optimization.ly2.em_steps = 0
learning.optimization.ly2.loops = 1
learning.optimization.ly2.merge_distance_threshold = 5.
learning.optimization.ly2.merge_sc_threshold     = 0.2

learning.optimization.ly3.part_max_number = 30
learning.optimization.ly3.cluster_size = 7
learning.optimization.ly3.library_image = lib3.png
learning.optimization.ly3.library_image_sc = lib3sc.png
learning.optimization.ly3.em_steps = 0
learning.optimization.ly3.loops = 2
learning.optimization.ly3.merge_distance_threshold = 6.
learning.optimization.ly3.merge_sc_threshold     = 0.1

learning.optimization.ly4.part_max_number = 50
learning.optimization.ly4.cluster_size = 10
learning.optimization.ly4.library_image = lib4.png
learning.optimization.ly4.library_image_sc = lib4sc.png
learning.optimization.ly4.show_labels = true
learning.optimization.ly4.em_steps = 0
learning.optimization.ly4.loops = 2
learning.optimization.ly4.merge_distance_threshold = 6.
learning.optimization.ly4.merge_sc_threshold     = 0.1

learning.optimization.ly5.part_max_number = 70
learning.optimization.ly5.cluster_size = 15
learning.optimization.ly5.library_image = lib5.png
learning.optimization.ly5.library_image_sc = lib5sc.png
learning.optimization.ly5.em_steps = 0
learning.optimization.ly5.loops = 2
learning.optimization.ly5.merge_distance_threshold = 5    # this is "pca" distance (norm)
learning.optimization.ly5.merge_sc_threshold     = 0.05

###########################################
########## Optimize layer 2 - 5 ###########
###########################################

# If the current set of parts covers at least <covered_threshold> percent of whole image, then optimization will not be done for that image
learning.optimization.ly2.optimize.covered_threshold	  = 0.95
learning.optimization.ly2.optimize.intersection_threshold = 0.1
learning.optimization.ly2.optimize.library_image_file     = lib2opt.png
learning.optimization.ly2.optimize.show_labels            = false
learning.optimization.ly2.optimize.optimization 	  = 0 # 1 .. default, 2 .. better but slower optimization, 0 .. none

learning.optimization.ly3.optimize.covered_threshold	  = 1.0
learning.optimization.ly3.optimize.intersection_threshold = 0.65,0.80
learning.optimization.ly3.optimize.library_image_file     = lib3opt.png
learning.optimization.ly3.optimize.show_labels            = false
learning.optimization.ly3.optimize.optimization 	  = 1,1

learning.optimization.ly4.optimize.covered_threshold	  = 1.
learning.optimization.ly4.optimize.intersection_threshold = 0.75,0.90
learning.optimization.ly4.optimize.library_image_file     = lib4opt.png # use if library is not very big!
learning.optimization.ly4.optimize.show_labels            = true
learning.optimization.ly4.optimize.optimization 	  = 1,1

learning.optimization.ly5.optimize.covered_threshold	  = 1.
learning.optimization.ly5.optimize.intersection_threshold = 0.8,0.95
learning.optimization.ly5.optimize.library_image_file     = lib5opt.png 
learning.optimization.ly5.optimize.show_labels            = true
learning.optimization.ly5.optimize.optimization 	  = 1,1


###########################################
######## Inference of layer 2 - 5 #########
###########################################

learning.optimization.ly2.infer.use_opencl = false
learning.optimization.ly3.infer.use_opencl = false
learning.optimization.ly4.infer.use_opencl = false
learning.optimization.ly5.infer.use_opencl = false

# import from inference namespace
learning.optimization.ly2.infer.from_namespace = inference.ly2
learning.optimization.ly3.infer.from_namespace = inference.ly3
learning.optimization.ly4.infer.from_namespace = inference.ly4
learning.optimization.ly5.infer.from_namespace = inference.ly5

###########################################
######## Learning of layer 2 - 5 #########
###########################################

#### config file for map update and part selection, layer 1 ####
################################################################
learning.optimization.ly2.source_layer_index = 1 # index + 1 of source layer
learning.optimization.ly2.learn.center_val_threshold_rel = 0.5 # def val = 0.5; only consider nodes with 
                                                               #   g-response > (1-~)-quantile of all nodes on lyr.
                                                               # smaller value, "more" we take
# if set, center_val_threshold is used!
#learning.optimization.ly2.learn.center_val_threshold = 0.8 #is used, if non-negative, def val = -1

# map update
learning.optimization.ly2.learn.nb_size = 17
learning.optimization.ly2.learn.nb_val_threshold_rel = 0.6     # nodes with (2-~)*(center val) > updat > ~*(center val.)
                                                               # def val = 0.6
learning.optimization.ly2.learn.seq_min_intersection_percent = 0.01    # def val = 0.0
learning.optimization.ly2.learn.seq_max_intersection_percent = 0.3     # def val = 0.5

# finding maxima
learning.optimization.ly2.learn.max_max = 4              # def val = 4 
learning.optimization.ly2.learn.max_val_threshold = 0.01 # def val = 0.01; only positions > max*~ are considered for
                                                         #   local maxima; max can be global max or map-local 
learning.optimization.ly2.learn.individual_max = false   # def val = false; take global od map-local max
learning.optimization.ly2.learn.max_sigma = 0.0          # def val = 0.0 sigma for "artificial" distribution
learning.optimization.ly2.learn.max_nbhood_mask = 5      # def val = 5; distribution size
learning.optimization.ly2.learn.max_radius = 2           # def val = 2; min distance between maxima or max and center 

# part update
learning.optimization.ly2.learn.max_candidates = 3    # def val = 5, no. of (best) candidates examined at each 
                                                      #   step when adding new subpart
learning.optimization.ly2.learn.min_part_length = 3   # def val = 2
learning.optimization.ly2.learn.max_part_length = 3
learning.optimization.ly2.learn.max_seq_size = 3      # def val = 3
learning.optimization.ly2.learn.seq_min_intersection_percent2 = 0.01    # def val = 0.0
learning.optimization.ly2.learn.seq_max_intersection_percent2 = 0.3     # def val = 0.5



#### config file for map update and part selection, layer 3 ####
################################################################
learning.optimization.ly3.source_layer_index = 2
learning.optimization.ly3.learn.center_val_threshold_rel = 0.1 # def val = 0.5; only consider nodes with 
                                                                #   g-response > (1-~)-quantile of all nodes on lyr.
                                                                # smaller value, "more" we take
#learning.optimization.ly3.learn.center_val_threshold = 0.5

# map update
learning.optimization.ly3.learn.nb_size = 19
learning.optimization.ly3.learn.nb_val_threshold_rel = 0.6     # nodes with (2-~)*(center val) > updat > ~*(center val.)
                                                               # def val = 0.6

learning.optimization.ly3.learn.seq_min_intersection_percent = 0.001   # def val = 0.0
learning.optimization.ly3.learn.seq_max_intersection_percent = 0.7    # def val = 0.5
learning.optimization.ly3.learn.seq_min_intersection_percent2 = 0.001    # def val = 0.0
learning.optimization.ly3.learn.seq_max_intersection_percent2 = 0.7    # def val = 0.5
 
# finding maxima
learning.optimization.ly3.learn.max_max = 5               # def val = 4 
learning.optimization.ly3.learn.max_val_threshold = 0.001 # def val = 0.01; only positions > max*~ are considered for
                                                          #   local maxima; max can be global max or map-local 
learning.optimization.ly3.learn.individual_max = true     # def val = false; take global od map-local max
learning.optimization.ly3.learn.max_sigma = 0.0           # def val = 0.0 sigma for "artificial" distribution
learning.optimization.ly3.learn.max_nbhood_mask = 5       # def val = 5; distribution size
learning.optimization.ly3.learn.max_radius = 2            # def val = 2; min distance between maxima or max and center 

# part update
learning.optimization.ly3.learn.max_candidates = 4    # def val = 5, no. of (best) candidates examined at each 
                                                      #   step when adding new subpart
learning.optimization.ly3.learn.min_part_length = 3   # def val = 2
learning.optimization.ly3.learn.max_seq_size = 3      # def val = 3


##### config file for map update and part selection, layer 4 ####
#################################################################
learning.optimization.ly4.source_layer_index = 3
#learning.optimization.ly4.learn.center_val_threshold = 0.7  
learning.optimization.ly4.learn.center_val_threshold_rel = 0.1 # def val = 0.5; only consider nodes with 
                                                               #   g-response > (1-~)-quantile of all nodes on lyr.
                                                               # smaller value, "more" we take
# map update
learning.optimization.ly4.learn.nb_size = 25
learning.optimization.ly4.learn.nb_val_threshold_rel = 0.6     # nodes with (2-~)*(center val) > updat > ~*(center val.)
                                                               # def val = 0.6
learning.optimization.ly4.learn.seq_min_intersection_percent = 0.01    # def val = 0.0
learning.optimization.ly4.learn.seq_max_intersection_percent = 0.6     # def val = 0.5
 
# finding maxima
learning.optimization.ly4.learn.max_max = 5               # def val = 4 
learning.optimization.ly4.learn.max_val_threshold = 0.005 # def val = 0.01; only positions > max*~ are considered for
                                                          #   local maxima; max can be global max or map-local 
learning.optimization.ly4.learn.individual_max = true     # def val = false; take global od map-local max
learning.optimization.ly4.learn.max_sigma = 0.0           # def val = 0.0 sigma for "artificial" distribution
learning.optimization.ly4.learn.max_nbhood_mask = 5       # def val = 5; distribution size
learning.optimization.ly4.learn.max_radius = 2           # def val = 2; min distance between maxima or max and center 

# part update
learning.optimization.ly4.learn.max_candidates = 3    # def val = 5, no. of (best) candidates examined at each 
                                                      #   step when adding new subpart
learning.optimization.ly4.learn.min_part_length = 3   # def val = 2
learning.optimization.ly4.learn.max_seq_size = 3      # def val = 3



##### config file for map update and part selection, layer 5 ####
#################################################################
learning.optimization.ly5.source_layer_index = 4
#learning.optimization.ly5.learn.center_val_threshold  = 0.8    # doesn't use ~_rel version below
learning.optimization.ly5.learn.center_val_threshold_rel = 0.1 # def val = 0.5; only consider nodes with 
                                                               #   g-response > (1-~)-quantile of all nodes on lyr.
                                                               # smaller value, "more" we take
# map update
learning.optimization.ly5.learn.nb_size = 31
learning.optimization.ly5.learn.nb_val_threshold_rel = 0.6     # nodes with (2-~)*(center val) > updat > ~*(center val.)
                                                               # def val = 0.6
learning.optimization.ly5.learn.seq_min_intersection_percent = 0.001    # def val = 0.0
learning.optimization.ly5.learn.seq_max_intersection_percent = 0.8     # def val = 0.5
 
# finding maxima
learning.optimization.ly5.learn.max_max = 6              # def val = 4 
learning.optimization.ly5.learn.max_val_threshold = 0.001 # def val = 0.01; only positions > max*~ are considered for
                                                         #   local maxima; max can be global max or map-local 
learning.optimization.ly5.learn.individual_max = true   # def val = false; take global od map-local max
learning.optimization.ly5.learn.max_sigma = 0.0          # def val = 0.0 sigma for "artificial" distribution
learning.optimization.ly5.learn.max_nbhood_mask = 5      # def val = 5; distribution size
learning.optimization.ly5.learn.max_radius = 2           # def val = 2; min distance between maxima or max and center 

# part update
learning.optimization.ly5.learn.max_candidates = 3    # def val = 5, no. of (best) candidates examined at each 
                                                      #   step when adding new subpart
learning.optimization.ly5.learn.min_part_length = 2   # def val = 2
learning.optimization.ly5.learn.max_seq_size = 3      # def val = 3



##########################################################################################################
########################################## Object learning ###############################################
##########################################################################################################



learning.learn_objects.contraction     = 1.5
learning.learn_objects.max_objects     = 100    # number of objects produced and validated, default = 4
learning.learn_objects.max_add         = 1      # number of objects finally added (out of max_objects)
learning.learn_objects.max_cluster_n   = 8      # max number of subparts default = 6 
learning.learn_objects.min_cluster_n   = 4      # min number of subparts default = 4
learning.learn_objects.cluster_size    = 2     # max number of similar parts
learning.learn_objects.max_depth       = 0
learning.learn_objects.layer           = 3
learning.learn_objects.gaussian_dim    = 5
learning.learn_objects.gaussian_sigma  = 1.5
learning.learn_objects.cluster_member_threshold  = 0.9     # similar parts thresh
learning.learn_objects.cover_threshold           = 0.81    # thresh for 'cover projection size'/'layer 0 size'
learning.learn_objects.intersection_threshold    = 0.6     # max intersection between subparts

learning.learn_objects2.from_file               = true
#learning.learn_objects2.library                 = from bat file
learning.learn_objects2.src_layer               = 4
#learning.learn_objects2.category_name           = from bat file
learning.learn_objects2.contraction             = 1.0
learning.learn_objects2.gaussian_dim            = 9
learning.learn_objects2.gaussian_sigma          = 2.5
learning.learn_objects2.cluster_member_threshold = 0.8   # similar parts thresh
learning.learn_objects2.cover_threshold         = 0.8    # thresh for 'cover projection size'/'layer 0 size'
learning.learn_objects2.intersection_threshold  = 0.8    # max intersection between subparts
learning.learn_objects2.max_cluster_n           = 5      # max number of subparts default = 6 
learning.learn_objects2.min_cluster_n           = 3      # min number of subparts default = 4
learning.learn_objects2.cluster_size            = 2      # max number of similar parts
learning.learn_objects2.hit_ratio_threshold     = 0.90   # hits/(hits + misses) >= ...
learning.learn_objects2.hit_threshold           = 0.01
learning.learn_objects2.intersection_quotient   = 0.1
learning.learn_objects2.type_bite_threshold     = 5      # take only ... best boxes for each type
learning.learn_objects2.redundancy_threshold    = 2     # if all boxes are hit > ... then validation image is skipped

learning.learn_objects2.validation.from_namespace               = inference.ly6
learning.learn_objects2.validation.realization_ratio_threshold  = 0.8
learning.learn_objects2.validation.new_positions_threshold      = 100


learning.learn_thresholds.category_layer    = 6
# learning.learn_thresholds.library           = olib.plb
# learning.learn_thresholds.out_library       = olibv.plb
learning.learn_thresholds.tf_ratio          = 0.85       # default = 0.75
learning.learn_thresholds.groundtruth_threshold = 0.6    # default = 0.7
learning.learn_thresholds.use_groundtruth   = true       # default = true
learning.learn_thresholds.object_layer_only = true       # default = false
learning.learn_thresholds.threshold_types = s

learning.learn_svm_thresholds.category_layer    = 6
# learning.learn_svm_thresholds.library           = olib.plb
# learning.learn_svm_thresholds.out_library       = olibv.plb
learning.learn_svm_thresholds.groundtruth_threshold = 0.7    # default = 0.7
learning.learn_svm_thresholds.remove_bad_parts = false    # default = true


learning.learn_hoc_classifier.category_layer    = 6
learning.learn_hoc_classifier.layers            = 1
learning.learn_hoc_classifier.bin_angles        = 6
learning.learn_hoc_classifier.bin_radii         = 30,140
learning.learn_hoc_classifier.box_grow_factor   = 1.2
# learning.learn_svm_thresholds.library           = olib.plb
# learning.learn_svm_thresholds.out_library       = olibv.plb
learning.learn_hoc_classifier.groundtruth_threshold = 0.65    # default = 0.7
learning.learn_hoc_classifier.remove_bad_parts = false    # default = true

